---
title: "Kümeleme Analizleri ve Uygulamaları"
author: "Ahu CEPHE, MsC."
date: "15 Mayıs 2022"
output:
  html_document: 
    df_print: default
    highlight: tango
    number_sections: no
    theme: cerulean
    toc: yes
    toc_depth: 3
    code_download: no
  pdf_document:
    toc: yes  
    extra_dependencies: "subfig"
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[CO,CE]{Kümeleme Analizleri ve Uygulamaları}
- \fancyfoot[CO,CE]{Copyright © 2022 Öğr. Gör. Ahu CEPHE}
- \fancyfoot[LE,RO]{\thepage}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, error = FALSE)
```

# KÜMELEME ANALİZLERİ
## Analiz Hazırlık Aşaması
### Kütüphanelerin Yüklenmesi

Kümeleme analizleri için kullanılacak olan kütüphaneler aşağıdaki kodlar çalıştırılarak yüklenir.

```{r load-libraries}
library(dplyr)
library(magrittr)
library(ggplot2)
library(factoextra)
library(gridExtra)
library(ClusterR)
library(fpc)
library(cluster)
library(stringr)
library(GGally)
library(NbClust)
library(mclust)
library(clValid)
library(tidyverse)  
library(dendextend) 
```

### Veri Okuma

Kümeleme analizleri için **iris** veri seti kullanılacaktır. Veri setinin "sınıf" sütununu içermemesi için son sütunu veri setinden çıkartılacaktır. Bu veri seti, her bir türden 50 örnek olmak üzere üç farklı yaprak çeşidine (setosa, virginica ve versicolor) ait toplamda 150 örnek sayısına sahip bir veri setidir. Her bir örnek için taç yaprak uzunluğu (petal.lenght), taç yaprak genişliği (petal.width), çanak yaprak genişliği (sepal.width) ve çanak yaprak uzunluğu (sepal.lenght) olmak üzere dört özellik belirlenmiştir. Amacımız; bu dört özelliğe sahip 150 örnek veri setine kümeleme algoritmaları uygulayarak yaprak çeşitlerini (kümeleri) bulmak.

Kümeleme analizlerinde kullanılacak olan iris veri seti aşağıdaki kod ile değişkene atılabilir ve değişken türleri kontrol edebilebilir.

```{r read-data}
# iris veri seti yüklenir
data <- iris[,-5]

# Veri setinin yapısı ve değişkenlerin veri türleri kontrol edilir
str(data)
```

Veri setindeki değişken isimleri, en üstten ve en alttan birkaç satır veriye ulaşmak için aşağıdaki kodlar kullanılır.

```{r head-data}
# Değişken isimleri
names(data)

# Veri setinde en üstten 5 satır döndürür
head(data)

# Veri setinde en alttan 5 satır döndürür
tail(data)
```

Değişkenlerin tanımlayıcı istatistikleri görüntülenebilir.

```{r summary}
# Değişkenlerin tanımlayıcı istatistikleri 
summary(data)
```

Veri setinde NA, NaN veya infinity değerler olup olmadığı kontrol edilir.

```{r null-data}
# Toplam NA'lar
f <- function(x){sum(is.na(x))}
sapply(data,f)%>%as.data.frame()

# Toplam infinite değerlerin kontrolü
f <- function(x){sum(is.infinite(x))}
sapply(data,f) %>% as.data.frame()

# Toplam NaN değerleri
f <- function(x){sum(is.nan(x))}
sapply(data,f)%>%as.data.frame()
```


### Değişken Dağılımlarının İncelenmesi
Değişkenlerin dağılımları histogram grafikleri ile incelenebilir.

```{r graphs}
# Histogram ve yoğunluk grafiği oluşturulur
histf<-function(z){
feature=str_replace_all(deparse(substitute(z)),"[data$]","")
ggplot(data) +
aes(x = z) +
geom_histogram(aes(y=..density..), position="identity", alpha=0.5,bins = 14L, fill = "#497AD2", colour = "blue") +
geom_density(alpha=0.2, fill = "#4411D2", colour = "#4411D2")+
labs(x =  paste("Özellik: ",feature),y = "Gözlem Numarası",
title = paste(feature, "İçin Histogram Grafiği"),
subtitle = paste(feature, "Özelliğinin Dağılımı"),
caption = "iris veri seti") +
theme_grey()
}

# 4 özellik için histogram grafikleri
histf(data$Sepal.Length)
histf(data$Sepal.Width)
histf(data$Petal.Length)
histf(data$Petal.Width)
```

Histogram grafiklerini topluca görebilmek için ise aşağıdaki kod çalıştırılabilir.

```{r hist}
iris1 <- as.data.frame(data)
iris1 %>%
  gather(attributes, value, 1:4) %>%
  ggplot(aes(x = value)) +
  geom_histogram(fill = 'lightblue2', color = 'black') +
  facet_wrap(~attributes, scales = 'free_x') +
  labs(x="Değerler", y="Sıklık") +
  theme_bw()
```

### Veri Standartlaştırma

Kümeleme analizlerinde verideki değişkenlerin birimlerinin incelenmesi ve eğer birim farklılığı varsa bu değişkenlerin standartlaştırılması gerekmektedir. 


```{r summarizing}
# özelliklerin ortalaması
apply(data,2,mean) %>% as.data.frame()

# özelliklerin varyansı
apply(data,2,var)%>%as.data.frame()

# özelliklerin kutu-çizgi grafikleri
boxplot(data, xlab="özellikler",ylab="değerler", main ="Özelliklerin Kutu-Çizgi Grafiği", col = "blue",
        border = "black",cex.axis=.5)
```

Özelliklerin kümeleme algoritması uygulamak için iyi ölçeklenmediği görülüyor. Bu nedenle, her özelliğin ortalaması 0 ve standart sapması 1 olacak şekilde ölçeklenmeli.

```{r scale}
# veri setini standartlaştır
data.scaled <- scale(data)

# standartlaştırılmış verinin özeti
summary(data.scaled)

# standartlaştırılmış verinin ortalaması
apply(data.scaled,2,mean)%>%as.data.frame()

# standartlaştırılmış verinin varyansı
apply(data.scaled,2,var)%>%as.data.frame()

# standartlaştırılmış özelliklerin kutu-çizgi grafikleri
boxplot(data.scaled, xlab="özellikler",ylab="değerler", main ="Özelliklerin Kutu-Çizgi Grafiği", col = "blue",border = "black",cex.axis=.5)
```

## Küme Sayısının Belirlenmesi

Bitki türleri bilinmeden yalnızca bitkilerin sepal ve petal uzunluklarının ve genişliklerinin bilinmesi ile bitki alt tür sayısı doğru olarak tahmin edilebilir mi?

Veri setindeki değişkenlere göre dağılım incelenir.

```{r cluster_number}
table(iris[,5])
library(relimp, pos=4)
car::scatterplotMatrix(~Petal.Length + Petal.Width + Sepal.Length + Sepal.Width, reg.line=FALSE, smooth=FALSE, spread=FALSE, span=0.5, id.n=0, diagonal = 'density', data=iris)
car::scatterplotMatrix(~Petal.Length + Petal.Width + Sepal.Length + Sepal.Width | Species, reg.line=FALSE, smooth=FALSE, spread=FALSE, span=0.5, id.n=0, diagonal= 'density', by.groups=TRUE, data=iris)
```

Olası küme sayısını görmek için korelasyon matrisinden oluşturulan heatmap grafiği incelenir.

```{r distance}
distance <- get_dist(data.scaled)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Her özellik arasındaki ilişkiyi anlamak için korelasyon değerleri ve saçılım grafikleri oluşturulur.

```{r scatter}
ggpairs(data)
```

Korelasyon grafiği:

```{r corr-graph}
# korelasyon grafiği
options(repr.plot.width=12, repr.plot.height=9)
ggcorr(data)
```
Temel bileşenler analizi ile olası küme sayısının tahmini:


```{r pca}
# Benzerlik matrisi
pca <- prcomp(data.scaled, center = TRUE,scale. = FALSE)

summary(pca)
```
Biplot grafiği:

```{r biplot}
# biplot
fviz_pca_biplot(pca)
```

## Benzerlik ve/veya Uzaklık Matrislerinin Oluşturulması

Benzerlik matrisi:

```{r disimilarity}
# Benzerlik matrisi
dist.eucl <-dist(data.scaled, method = "euclidean")
dim(dist.eucl)
head(dist.eucl)

```



## Kümeleme Algoritmaları
### k-ortalamalar Kümelemesi

Özellikleri:

* Klinik problemlerin çözümünde hiyerarşik kümeleme algoritması kadar yaygın kullanılır.
* Partition algoritmasını kullanır.
* Her kümenin merkezi tarafından sunulan uzaklık-tabanlı bir algoritmadır.
* Ahlqvist ve ark. beş değişkeni temel alarak diyabetik bireyleri tabakalamak için hiyerarşik kümelemeye ek olarak k-means
uygulaması kullandı.
* Kalp yetmezliği hastalarının sınıflandırılması ve bir k-ortalama kümeleme algoritmasının kullanılması ile ilgili olarak, Ahmad ve ark.sadece sonuçlarda değil, aynı zamanda terapötiklere yanıtta da önemli ölçüde farklılık gösteren dört klinik farklı fenotip tanımladı.

R paketleri:

* Stats::kmeans() (Sadece Öklid uzaklığını kullanır ve sadece sayısal değişkenler için)
* amap::kmeans() (Sadece sayısal değişkenleri kullanır ancak, Öklid ten farklı bir uzaklık ölçüsü seçebilir.)
* clustMixType (Karışık veri türlerini kabul eder)

Avantajları:

* Uygulamak ve anlamak basit
* Büyük veri setleri için hızlı ve etkili

Dezvantajları:

* Küme sayılarının belirlenmesi gerekliliği
* Rastgele seçilen merkezlere duyarlılık
* Bazı uygulamaların sadece Öklid uzaklığını kullanması


Veri setine k-ortalamalar kümelemesi uygulanırken öncelikle optimum küme sayısı bulunur.

1) Optimum küme sayısı (Elbow yöntemi):

```{r elbow}
# Elbow yöntemi

fviz_nbclust(data.scaled, kmeans, method = "wss")+
geom_vline(xintercept = 3, linetype = 2)+labs(subtitle = "Elbow Yöntemi")
```

2) Optimum küme sayısı (Silhouette yöntemi):

```{r silhouette}
# Silhouette yöntemi
fviz_nbclust(data.scaled, kmeans, method = "silhouette")+labs(subtitle = "Silhouette Yöntemi")
```

3) Optimum küme sayısı (Gap istatistiği):

```{r gap}
# Gap istatistiği
set.seed(123)
fviz_nbclust(data.scaled, kmeans, nstart = 25, method = "gap_stat", nboot = 50)+labs(subtitle = "Gap İstatistik Yöntemi")
```

4) Optimum küme sayısı (NbClust() yöntemi):

```{r nbclust}
nb <- NbClust(as.matrix(data.scaled[,-c(5)]), distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "all")
# Sonuçlar
nb
table(nb$Best.nc[1,])
```

k-ortalamalar kümelemesinde center=3 ile küme sayısı 3 olarak belirlendi. nstarts seçeneği, çoklu ilk konfigürasyonları oluşturup, en iyi olanı raporlar.

```{r kort}
# k = 3 kümeye göre k-ortalamalar kümelemesi

set.seed(123)
km.res <- kmeans(data.scaled, centers = 3, nstart = 25)
str(km.res)
summary(km.res)
km.res
table(km.res$cluster, iris[,5])
```

```{r kort-graph1}
# k-ortalamalar sonuçlarının görselleştirilmesi
fviz_cluster(km.res, data = data.scaled)

```

```{r kort-graph}
# k-ortalamalar sonuçlarının görselleştirilmesi
fviz_cluster(km.res, data = data.scaled,
palette = c( "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", 
star.plot = TRUE, 
repel = TRUE, 
ggtheme = theme_minimal())

```

Farklı küme sayıları ile k-ortalamalar algoritması grafikleri aşağıdaki kodlar ile gösterilir.

```{r different_clusters}
k4 <- kmeans(data.scaled, centers = 4, nstart = 25)
k5 <- kmeans(data.scaled, centers = 5, nstart = 25)
k6 <- kmeans(data.scaled, centers = 6, nstart = 25)

# Grafikleri karşılaştır
p1 <- fviz_cluster(km.res, geom = "point", data = data.scaled) + ggtitle("k = 3")
p2 <- fviz_cluster(k4, geom = "point",  data = data.scaled) + ggtitle("k = 4")
p3 <- fviz_cluster(k5, geom = "point",  data = data.scaled) + ggtitle("k = 5")
p4 <- fviz_cluster(k6, geom = "point",  data = data.scaled) + ggtitle("k = 6")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

Ortalama için;

```{r ortalama}
# kümeleri faktöre çevir
km.res$cluster <- as.factor(km.res$cluster)

# orjinal iris veri seti kümeye atanır
data.clust.kmeans <- cbind(data, cluster = km.res$cluster)

# kümeye göre özellikler toplanır
aggar.kmeans <- aggregate(data.clust.kmeans[,1:4], by=list(data.clust.kmeans$cluster), mean) %>% as.data.frame()

aggar.kmeans%>%knitr::kable()
```

```{r visualize}
ggpairs(data.clust.kmeans,aes(color=cluster, alpha=0.5),lower = list(combo = wrap("facethist"))
        ,upper = list(continuous = wrap('cor', size = 1)),binwidth = 0.1) + theme(strip.text = element_text(size = 2))
```

### k-medoids Kümelemesi

Özellikleri:

* k-ortalamalar ile ilişkili bir algoritmadır. Ancak, k-ortancalar de her küme, o gruptaki diğer tüm üyeler arasındaki ortalama farklılığı (ortanca) en aza indiren gözlemle temsil edilir.
* k-ortancalar, k-means’ten daha sağlam bir algoritma olarak kabul edilse de, gerçek klinik veri kümelerinde mutlaka daha iyi performans göstermez.

R paketleri:

* Cluster::pam() (Öklid ve Manhattan uzaklıklarını kullanır, sadece sayısal değişkenlere uygulanır)
* fpc::pamk() (Önerilen K’yi Silhouette göre yazdırır, kullanıcının küme sayısını tanımlamasını gerektirmez)

Avantajları:

* Uygulamak ve anlamak basit
* Gürültüye ve aykırı değerlere k-ortalamalar kümeleme algoritmasından daha az duyarlı
* Nesnelerin genel benzemezliğini kullanmaya izin vermesi

Dezavantajları:

* Küme sayılarının belirlenmesi gerekliliği
* Medoidlerin rasgele başlangıçlara duyarlılığı
* k-ortalamalar kümeleme algoritmasından daha yüksek hesaplama maliyetine sahip olma
* Küresel ve dışbükey kümeleri tanımlamaya daha yatkın
* Büyük veri kümeleri için iyi ölçeklenmemesi

k-ortancalar kümeleme algoritmasının büyük veri kümeleri ile başa çıkabilmesi için k-ortancalar (CLARA) algortiması oluşturuldu! Bu algoritma cluster::clara() fonksiyonunu kullanır.

Veri setine k-medoids kümelemesi uygulanırken öncelikle optimum küme sayısı bulunur.

1) Optimum küme sayısı (Elbow yöntemi):

```{r elbow2}
# Elbow yöntemi
fviz_nbclust(data.scaled, pam, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)+
labs(subtitle = "Elbow Yöntemi")
```

2) Optimum küme sayısı (Silhouette yöntemi):

```{r silhouette2}
# Silhouette yöntemi
fviz_nbclust(data.scaled, pam, method = "silhouette")+
labs(subtitle = "Silhouette Yöntemi")
```

3) Optimum küme sayısı (Gap istatistiği):

```{r gap2}
# Gap istatistiği
fviz_nbclust(data.scaled, pam, method = "silhouette")+labs(subtitle = "Silhouette Yöntemi")
```

Veri seti için karar verilern küme sayısı 3'tür. k-medoid kümelemesi aşağıdaki gibi uygulanır.

```{r kmed}
# k=3 ile k-medoid kümelemesi
pam.res <- pam(data.scaled, 3)
table(pam.res$cluster, iris[,5])
```

```{r kmed-graph}
# kümelerin görselleştirilmesi
fviz_cluster(pam.res,
palette = c("#00AFBB", "#FC4E07","#00AB33"), 
ellipse.type = "t", 
repel = TRUE, 
ggtheme = theme_classic()
)
```

Ortalama için;

```{r ortalama2}
# kümeler faktör haline getirilir
pam.res$cluster <- as.factor(pam.res$cluster)

# iris veri setine küme atanır
data.clust.pam <- cbind(data, cluster = pam.res$cluster)

# kümelenmiş verileri kümeye göre toplama
aggregate(data.clust.pam[,1:4], by=list(cluster=km.res$cluster), mean)%>%knitr::kable()
```

```{r visualize2}
ggpairs(data.clust.pam,aes(color=cluster, alpha=0.5),lower = list(combo = wrap("facethist"))
        ,upper = list(continuous = wrap('cor', size = 1)),binwidth = 0.1) + theme(strip.text = element_text(size = 2))
```

### Model-tabanlı Kümeleme

Özellikleri:

* İki veya daha fazla kümenin olasılık dağılımlarının bir karışımıdır.
* Bu metodoloji için EM algoritması, son karışım olasılıklarının parametrelerini tahmin etmek için en yaygın şekilde kullanılanıdır.
* Tıbbi görüntü alanındaki bazı klinik sorunları çözmek için başarıyla uygulanmıştır. Örneğin, bir EM kümeleme algoritması kullanan Hwang, Wireless Kapsül Endoskopi videolarında bağırsak kanama bölgelerini otomatik olarak tespit etmek için bir teknik önerdi.

R paketleri:

* mclust::mclust()

Avantajları:

* Uygulama basitliği
* Veriye bir model uydurabilme kabiliyeti
* Kümes sayısının önceden bilinmesini gerektirmeme
* Eksik değerlerle başedebilme

Dezavantajları:

* Yavaş yakınsama hızı
* Gözlem sayısı az olan ve eşdoğrusallık sorunları olan kümeler için uygun değildir


```{r model-based}
mc<-Mclust(data.scaled)
mc$G
table(mc$classification, iris[,5])
```

```{r model-visual}
# Classification: kümelemeyi göstererek grafikler
fviz_mclust(mc, "classification", geom = "point",pointsize = 1.5, palette = "jco")
```

```{r model-ort}
# kümeler faktör haline getirilir
mc$classification <- as.factor(mc$classification)

# orjinal veri seti kümelere atanır
data.clust.gmm <- cbind(data, cluster = mc$classification)

# kümelenmiş verileri kümeye göre toplama
aggregate(data.clust.gmm[,1:4], by=list(data.clust.gmm$cluster), mean)%>%knitr::kable()
```

```{r model-graph}
ggpairs(data.clust.gmm,aes(color=cluster, alpha=0.5),lower = list(combo = wrap("facethist"))
        ,upper = list(continuous = wrap('cor', size = 1)),binwidth = 0.1) + theme(strip.text = element_text(size = 2))
```

### Hiyerarşik Kümeleme

Aşamalı bir yapıdan oluşur ve bir alt aşamadaki küme alt grupları bir sonraki aşamadaki kümeleri oluşturmak için bir araya getirilir. Uzaklık veya benzerlik ölçülerini dikkate alır.

* Birleştirici (agglomerative) aşamalı kümeleme yöntemi: Her gözlem başlangıçta tek başlarına ayrı birer küme olarak kabul edilir. Sonra, her adımda, en yakın iki gözlem yeni bir küme içinde birleştirilir. En sonunda, tüm bireyler bir küme içinde toplanır.

* Ayırıcı (divisive) aşamalı kümeleme yöntemi: Tüm gözlemler başlangıçta bir küme içerisindedir. Sonra, her adımda en farklı (uzak) gözlemler birbirinden ayrılarak daha küçük kümeler oluşturulur. En sonunda, her gözlem tek başına ayrı bir küme haline gelir.

Özellikleri:

* Klinikte en sık kullanılan kümeleme algoritmasıdır.
* Yığılımlı (bottom-up/agglomerative) ve bölücü (top-down/divisive) yaklaşımları kullanır.
* Bu iki yaklaşımdan biri ile birleştirilen kümeler genellikle ağaç grafiği (dendogram) ile sunulur.
* Küme sayısı belirlemede tercih edilir.
* Bir benzemezlik matrisi oluşturur.
* Biyoinformatikte omik alanda; klinikte Pulmonolojik, ramatolojik ve metabolik hastalıklar gibi çok farklı düzenlerdeki problemleri ele almada sıklıkla kullanılır.

R paketleri:

* Yığınsal Hiyerarşik Kümeleme: stat::hclust(), Cluster::agnes()
* Bölücü Hiyerarşik Kümeleme: cluster::diana()
* Dendextend paketi

Avantajları:

* Küme sayısının önceden bilinmesini gerektirmez
* Herhangi bir uzaklık fonksiyonu türünü kullanabilir
* Görsel bakımdan zengindir
* Küçük kümeleri tanımlamada yığınsal hiyerarşik kümeleme iyi iken, büyük kümeleri tanımlamada bölücü hiyerarşik kümeleme daha iyidir

Dezavantajları:

* Yüksek hesaplama maliyeti
* Analiz başladığında değişim yapmak çok zor
* Bağlantı fonksiyonlarına göre farklı küme sonuçları elde edebilir
* Küresel ve dışbükey kümeleri tanımlamaya daha yatkın
* Kofenetik mesafe kesmesini tanımlamak gerekliliği
* Aykırı değerlere duyarlılık

Linkage yöntemi küme sayısını etkiler.

1) Optimum küme sayısı (Elbow yöntemi):

```{r elbow3}
# Elbow yöntemi
fviz_nbclust(data.scaled, hcut, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)+
labs(subtitle = "Elbow Yöntemi")
```

2) Optimum küme sayısı (Silhouette yöntemi):

```{r silhouette3}
# Silhouette yöntemi
fviz_nbclust(data.scaled, hcut, method = "silhouette")+
labs(subtitle = "Silhouette Yöntemi")
```

3) Optimum küme sayısı (Gap istatistiği):

```{r gap3}
# Gap istatistiği
set.seed(123)
fviz_nbclust(data.scaled, hcut, nstart = 25, method = "gap_stat",
nboot = 50)+
labs(subtitle = "Gap İstatistik Yöntemi")
```

Tam Bağlantı (Complete Linkage): Başlangıçta uzaklıklar matrisindeki en küçük uzaklık ile kümelemeye başlanır, ancak daha sonra, kümeleme sürecinde oluşturulacak yeni iki küme arasındaki uzaklık olarak kümelerdeki gözlemler arasındaki en büyük uzaklık dikkate alınır. 

Çoğunluk kuralına göre "tam bağlantı (complete)" için hiyerarşik kümelemede optimum küme sayısı:

```{r hiy-nbclust1}
# complete bağlantısı
nb.complete <- NbClust(data.scaled, distance = "euclidean", min.nc = 2,max.nc = 10, method = "complete", index = "ch")

# sonuçlar görselleştirilir
fviz_nbclust(nb.complete)
```

Ward Yöntemi: En küçük varyans yöntemi olarak bilinir. Az gözlemli kümeleri birleştirme eğilimindedir. Ayrıca, eşit sayıda gözlemden oluşan kümeler oluşturma eğilimi de olduğundan daha çok birbirine yakın gözlem sayısına sahip kümeleme beklentilerinin olduğu durumlarda kullanılır.

Çoğunluk kuralına göre "ward bağlantı" için hiyerarşik kümelemede optimum küme sayısı:

```{r hiy-nbclust2}
# ward bağlantısı
nb.ward2 <- NbClust(data.scaled, distance = "euclidean", min.nc = 2,max.nc = 10, method = "ward.D", index = "ch")
options(repr.plot.width=12, repr.plot.height=9)

# sonuçlar görselleştirilir
fviz_nbclust(nb.ward2)
```

Ortalama Bağlantı (Average Linkage): Bir kümedeki tüm bireylerden elde edilen ortalama uzaklığın diğer kümedeki tüm bireylere olan ortalama uzaklığı kullanılarak hesaplanır.

Çoğunluk kuralına göre "ortalama bağlantı (average)" için hiyerarşik kümelemede optimum küme sayısı:

```{r hiy-nbclust3}
# average bağlantısı
nb.avg <- NbClust(data.scaled, distance = "euclidean", min.nc = 2,max.nc = 10, method = "average", index = "ch")

# sonuçlar görselleştirilir
fviz_nbclust(nb.avg)
```

Elde edilen optimum k değerine göre küme oluşturulur ve buna göre dendrogram görselleştirip kesilir:

```{r hiy-dend}
# euclidean uzaklık matrisi oluşturulur
dist.mat <- dist(data.scaled, method = "euclidean")

# farklı bağlantılara göre hiyerarşik kümeleme uygulanır
hc.comp<-hclust(dist.mat,method = "complete")
hc.ward<-hclust(dist.mat,method = "ward.D2")
hc.avg<-hclust(dist.mat,method = "average")
```

Complete bağlantısı (k=3):

```{r hiy-comp}
options(ggrepel.max.overlaps = Inf)
# Complete bağlantısı (k=3)
# kümeler 3 grupta toplanır ve farklı kümeler farklı renklerle gösterilir
fviz_dend(hc.comp, k = 3, # Cut in three groups
cex = 0.5, # label size
k_colors = c("#2E00DF", "#55AFBB", "#E7B800"),
color_labels_by_k = TRUE, # color labels by groups
rect = TRUE,
rect_fill=F,main = "Dendrogram - Complete (k=3)",
xlab = "Nesneler", ylab = "Uzaklık", sub = "",
ggtheme = theme_minimal()
)
```

Ward.D2 bağlantısı (k=3):

```{r hiy-ward}
# Ward.D2 bağlantısı (k=3)
# kümeler 3 grupta toplanır ve farklı kümeler farklı renklerle gösterilir
fviz_dend(hc.ward, k = 3, 
cex = 0.5, # label size
k_colors = c("#2E00DF", "#55AFBB", "#E7B800"),
color_labels_by_k = TRUE, # color labels by groups
rect = TRUE,
rect_fill=F,main = "Dendrogram - Complete (k=3)",
xlab = "Nesneler", ylab = "Uzaklık", sub = "",
ggtheme = theme_minimal()
)
```

Average bağlantısı (k=3):

```{r hiy-ave}
# Average bağlantısı (k=3)
# kümeler 3 grupta toplanır ve farklı kümeler farklı renklerle gösterilir
fviz_dend(hc.avg, k = 3, 
cex = 0.5, # label size
k_colors = c("#2E00DF", "#55AFBB", "#E7B800"),
color_labels_by_k = TRUE, 
rect = TRUE,
rect_fill=F,main = "Dendrogram - Complete (k=3)",
xlab = "Nesneler", ylab = "Uzaklık", sub = "",
ggtheme = theme_minimal()
)
```

Average bağlantısı (k=8):

```{r hiy-ave2}
# Average bağlantısı (k=8)
#  kümeler 8 grupta toplanır ve farklı kümeler farklı renklerle gösterilir
fviz_dend(hc.avg, k = 8, 
cex = 0.5, # label size
k_colors = c("#2E00DF", "#55AFBB", "#E7B800"),
color_labels_by_k = TRUE, 
rect = TRUE,
rect_fill=F,main = "Dendrogram - Complete (k=3)",
xlab = "Nesneler", ylab = "Uzaklık", sub = "",
ggtheme = theme_minimal()
)
```

Ortalama tablosu:

```{r hiy-ort}
# dendoram 3 küme olarak oluşturulur (complete bağlantısı) 
grp.comp <- cutree(hc.comp,3)

# kümeler faktöre çevrilir
grp.comp <- as.factor(grp.comp)

# orjinal veri seti kümelere atanır
data.clust.hier <- cbind(data, cluster = grp.comp)

# kümelenmiş verileri kümeye göre toplama
aggregate(data.clust.hier[,1:4], by=list(data.clust.hier$cluster), mean)%>%knitr::kable()
```

```{r hiy-graph}
ggpairs(data.clust.hier,aes(color=cluster, alpha=0.5),lower = list(combo = wrap("facethist"))
        ,upper = list(continuous = wrap('cor', size = 1)),binwidth = 0.1) + theme(strip.text = element_text(size = 2))
```

## Küme Sonuçlarını Karşılaştırma

```{r compare1}
xtabs(~data.clust.kmeans$cluster+data.clust.pam$cluster)
```

```{r compare2}
xtabs(~data.clust.kmeans$cluster+data.clust.gmm$cluster)
```

```{r compare3}
xtabs(~data.clust.kmeans$cluster+data.clust.hier$cluster)
```

```{r compare4}
xtabs(~data.clust.pam$cluster+data.clust.gmm$cluster)
```

```{r compare5}
xtabs(~data.clust.pam$cluster+data.clust.hier$cluster)
```

```{r compare6}
xtabs(~data.clust.gmm$cluster+data.clust.hier$cluster)
```

## Model Seçimi

İç geçerlilik ölçümleri: Connectivity, 0 ile sonsuz arasında bir değere sahiptir ve en aza indirilmelidir. Silhouette değeri, belirli bir kümeleme atamasındaki güven derecesini ölçer ve iyi kümelenmiş gözlemlerin 1'e yakın değerlere sahip olduğu ve zayıf kümelenmiş gözlemlerin -1'e yakın değerlere sahip olduğu [-1,1] aralığında yer alır. Dunn İndeksi, aynı kümede olmayan gözlemler arasındaki en küçük mesafenin en büyük küme içi mesafeye oranıdır.

```{r model-selection}
# Model seçimi 
suppressPackageStartupMessages( library(clValid))

clmethods <- c("hierarchical","kmeans","pam","model") 
intern <- clValid(data.scaled, nClust = 3,clMethods = clmethods, validation = "internal",method="complete")

# Özet
summary(intern)
```

Stability ölçümleri: Stability ölçüleri, bir kümeleme sonucunun kararlılığını, her seferinde bir sütun kaldırılarak elde edilen kümelerle karşılaştırarak değerlendiren dahili ölçülerin özel bir versiyonudur. Bu ölçüler; the average proportion of non-overlap (APN), the average distance (AD), the average distance between means (ADM), and the figure of merit (FOM) dir. APN, aynı kümeye yerleştirilmeyen gözlemlerin ortalama oranını ölçerken, AD, aynı kümeye yerleştirilen gözlemler arasındaki ortalama mesafeyi ölçer. ADM, aynı kümeye yerleştirilen gözlemler için küme merkezleri arasındaki ortalama mesafeyi ölçer.FOM, kümelemenin kalan (silinmemiş) sütunları temel aldığı, silinen sütunun ortalama küme içi varyansını ölçer.

```{r model-selection2}
# Stability ölçümler
clmethods <- c("hierarchical","kmeans","pam","model")  

stab <- clValid(data.scaled, nClust = 3, clMethods = clmethods,validation = "stability",method="complete")

# Sadece optimal skorları göster
optimalScores(stab)%>%knitr::kable()
```



